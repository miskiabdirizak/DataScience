{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant         int64\n",
      "dteday         object\n",
      "season          int64\n",
      "yr              int64\n",
      "mnth            int64\n",
      "holiday         int64\n",
      "weekday         int64\n",
      "workingday      int64\n",
      "weathersit      int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "hum           float64\n",
      "windspeed     float64\n",
      "casual          int64\n",
      "registered      int64\n",
      "cnt             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#  load a bike share toy dataset we will use for building these classifiers\n",
    "data = pd.read_csv('bike_sharing_daily.csv')\n",
    "print(data.dtypes)\n",
    "\n",
    "desc_features = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum',\n",
    "                 'windspeed', 'cnt']\n",
    "data = data[desc_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season        0\n",
       "mnth          0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# two-step numeric imputer (using Simple mean imputing) and standard scaling)\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
    "                                      ('scaler', StandardScaler())\n",
    "                                     ]\n",
    "                              )\n",
    "\n",
    "# two-step categorical imputer (using Simple imputing and ordinal encoder)\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant'))\n",
    "                                          ,('encoder', OrdinalEncoder())\n",
    "                                         ]\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard-coded numerical and categorical features\n",
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "\n",
    "# create a preprocessing tranformer \n",
    "# ColumnTransformer will allow different features to be transformed separately \n",
    "# and the features generated by each transformer will be concatenated to form a single feature space. \n",
    "preprocessor = ColumnTransformer(transformers=[('numeric', numeric_transformer, numeric_features),\n",
    "                                               ('categorical', categorical_transformer, categorical_features)\n",
    "                                              ]\n",
    "                                ) \n",
    "# the above preprocessor transformer will apply numeric_transformer to numeric_features \n",
    "# and categorical_transformer to categorical_features. These are pipelines defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# now we build a preprocessing+training pipeline to use for our analytics task.\n",
    "# this pipeline will apply the preprocessor transformer for numeric and categorical features separately\n",
    "# then it will use a random forest regressor initialized.\n",
    "reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', RandomForestRegressor(n_estimators=20, max_depth=3))\n",
    "                          ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# prepare training and testing data, cnt (count) is the target variable for the regression problem\n",
    "X = data.drop('cnt',axis=1)\n",
    "y = data['cnt']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('preprocessor',\n",
      "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
      "                                   sparse_threshold=0.3,\n",
      "                                   transformer_weights=None,\n",
      "                                   transformers=[('numeric',\n",
      "                                                  Pipeline(memory=None,\n",
      "                                                           steps=[('imputer',\n",
      "                                                                   SimpleImputer(add_indicator=False,\n",
      "                                                                                 copy=True,\n",
      "                                                                                 fill_value=None,\n",
      "                                                                                 missing_values=nan,\n",
      "                                                                                 strategy='mean',\n",
      "                                                                                 verbose=0)),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler(copy=True,\n",
      "                                                                                  with_me...\n",
      "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
      "                                       criterion='mse', max_depth=3,\n",
      "                                       max_features='auto', max_leaf_nodes=None,\n",
      "                                       max_samples=None,\n",
      "                                       min_impurity_decrease=0.0,\n",
      "                                       min_impurity_split=None,\n",
      "                                       min_samples_leaf=1, min_samples_split=2,\n",
      "                                       min_weight_fraction_leaf=0.0,\n",
      "                                       n_estimators=20, n_jobs=None,\n",
      "                                       oob_score=False, random_state=None,\n",
      "                                       verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "rf_pipe_model = reg_pipeline.fit(X_train, y_train)\n",
    "print (rf_pipe_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score:0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# we can now test the pipelined random forest model we created with the test data\n",
    "predictions = rf_pipe_model.predict(X_test)\n",
    "\n",
    "# and check the explained variance\n",
    "print(\"R2 score:{:.2f}\".format(r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "Model R2 score:-0.049862\n",
      "\n",
      "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "Model R2 score:-0.823941\n",
      "\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Model R2 score:0.273401\n",
      "\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "Model R2 score:-4194.651585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# next we will test different regressors for the same task.\n",
    "# we will use linear regression, elastic net, grad boosting and support vector machine regressors\n",
    "\n",
    "regressors = [LinearRegression(), \n",
    "              ElasticNet(),\n",
    "              GradientBoostingRegressor(),\n",
    "              SVR()\n",
    "             ]\n",
    "\n",
    "# for each regressor, use the same preprocessor transformer and add the regressor to the custom pipe\n",
    "for reg_ in regressors:\n",
    "    \n",
    "    reg_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor',reg_)\n",
    "                              ]\n",
    "                       )\n",
    "    # train and test\n",
    "    model = reg_pipe.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print(reg_)\n",
    "    print('Model R2 score:{:2f}\\n'.format(r2_score(predictions, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./rf_reg_model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "import joblib\n",
    "\n",
    "# using joblib library, you can pickle (save) your models [or data/settings]\n",
    "# we will save our piped random forest model as it provided the best performance\n",
    "joblib.dump(rf_pipe_model, './rf_reg_model.pkl')\n",
    "# the pickled model will be stored in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5628.00394627, 5850.78313231, 2024.44802212, 1913.27250348,\n",
       "       3316.31885362, 3177.07212479, 5212.97002087, 5090.76857632,\n",
       "       3869.86437687, 1913.27250348, 1852.18294955, 3105.93356654,\n",
       "       3467.04658337, 5629.94504692, 5884.85642459, 5631.22977874,\n",
       "       5732.73308504, 4182.00425613, 2817.21316038, 3723.02417573,\n",
       "       6133.04678214, 2101.11325604, 4177.56720168, 5631.22977874,\n",
       "       1774.01628289, 5735.82411949, 5826.45491919, 6133.04678214,\n",
       "       5701.79446921, 5710.10126476, 1852.18294955, 5989.9434514 ,\n",
       "       4773.90962297, 5667.90311117, 3467.04658337, 3165.57450676,\n",
       "       5529.34538793, 5832.28079182, 3467.04658337, 4289.2962131 ,\n",
       "       5315.57443625, 3467.04658337, 5626.98518664, 3467.04658337,\n",
       "       5757.53523032, 5998.90400048, 2524.0892269 , 5297.96539595,\n",
       "       2437.93635618, 2423.56214493, 5554.4075923 , 5715.11523817,\n",
       "       5647.12602367, 5628.00394627, 5340.16354955, 4731.71146937,\n",
       "       4065.3648451 , 5090.76857632, 5850.78313231, 2437.93635618,\n",
       "       5630.11986309, 3375.95979385, 3015.31657094, 5732.73308504,\n",
       "       5930.93935016, 3994.00611957, 5692.83392013, 5505.44404451,\n",
       "       5297.96539595, 4182.00425613, 5636.96449535, 5891.04018526,\n",
       "       3410.44161459, 5850.78313231, 6142.00733122, 5508.39446228,\n",
       "       5628.00394627, 5924.75558949, 3424.90927318, 2179.27992271,\n",
       "       5832.28079182, 4220.65034823, 6172.94594704, 2817.21316038,\n",
       "       4581.65953356, 5771.66305164, 5930.93935016, 5611.24631175,\n",
       "       4012.23569006, 5297.96539595, 1774.01628289, 2799.46188285,\n",
       "       5792.38162692, 5529.34538793, 5243.90863669, 2821.42053388,\n",
       "       2862.20489113, 5884.85642459, 5884.85642459, 2407.49587999,\n",
       "       4115.94869533, 5080.26011564, 3564.89377226, 5704.09345791,\n",
       "       4065.3648451 , 5832.28079182, 6197.876756  , 5715.67979046,\n",
       "       3809.39531583, 3526.93494705, 5286.10679029, 5297.96539595,\n",
       "       4115.94869533, 3526.6875236 , 1841.49263487, 5925.11347753,\n",
       "       5665.30307101, 5256.98305957, 5611.24631175, 3869.86437687,\n",
       "       2821.42053388, 5631.22977874, 5636.96449535, 3467.04658337,\n",
       "       5297.42003259, 4258.46316888, 2821.42053388, 5628.00394627,\n",
       "       2817.21316038, 5667.90311117, 3396.56036178, 5529.34538793,\n",
       "       1817.71544955, 4299.25224481, 2821.42053388, 5577.17301948,\n",
       "       5667.90311117, 5661.6230312 , 5735.27875613, 5631.22977874,\n",
       "       3641.95029361, 5636.96449535, 4430.98118286, 4182.00425613,\n",
       "       4204.40640962, 6172.94594704, 5667.90311117, 3085.4527662 ,\n",
       "       5965.01264243, 5665.30307101, 5628.00394627, 4161.8774408 ,\n",
       "       5587.74689333, 3923.77797578, 1913.27250348, 5771.66305164,\n",
       "       5930.93935016, 5832.28079182, 2630.82946838, 4115.94869533,\n",
       "       4274.07979739, 5661.89530431, 3657.24585552, 5237.56414487,\n",
       "       2179.27992271, 5611.44270643, 2202.72354159, 5667.90311117,\n",
       "       3871.63951131, 5297.96539595, 5925.11347753, 4350.98554035,\n",
       "       5667.90311117, 6102.10816631, 5832.28079182, 4065.3648451 ,\n",
       "       2757.57222016, 5681.0419459 , 4025.92999863, 1852.18294955,\n",
       "       4790.41233228, 3245.83263203, 1980.74885546])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can load it back \n",
    "loaded_rf_model = joblib.load('./rf_reg_model.pkl')\n",
    "\n",
    "new_data = X_test\n",
    "\n",
    "new_prediction = loaded_rf_model.predict(new_data)\n",
    "new_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='mean',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_me...\n",
       "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                       criterion='mse', max_depth=3,\n",
       "                                       max_features='auto', max_leaf_nodes=None,\n",
       "                                       max_samples=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=20, n_jobs=None,\n",
       "                                       oob_score=False, random_state=None,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the loaded rf pipeline\n",
    "loaded_rf_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
