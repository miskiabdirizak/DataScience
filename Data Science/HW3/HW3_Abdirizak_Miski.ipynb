{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Price Prediction\n",
    "\n",
    "In this homework, you will analyze and create a predictive model for predicting the price range of mobile phones using a dataset that describes the features of mobile phones. Each row in the dataset represents the specifications of a mobile phone and the target feature is an ordinal variable representing the price range. This dataset that has the following descriptive features. \n",
    "\n",
    "- battery_power: Battery power in mAh\n",
    "- blue: Has bluetooth or not\n",
    "- clock_speed: Processor clock speed\n",
    "- dual_sim: Has dual sim support or not\n",
    "- fc: Front Camera mega pixels\n",
    "- four_g: Has 4G or not\n",
    "- int_memory: Internal Memory in Gigabytes\n",
    "- m_dep: Depth of the phone in cm\n",
    "- mobile_wt: Weight of the phone\n",
    "- n_cores: Number of cores of processor\n",
    "- pc: Primary Camera mega pixels\n",
    "- px_height: Pixel Resolution Height\n",
    "- px_width: Pixel Resolution Width\n",
    "- ram: RAM in Megabytes\n",
    "- sc_h: Screen height in cm\n",
    "- sc_w: Screen Width in cm\n",
    "- talk_time: Longest talk time in hours\n",
    "- three_g: Has 3G or not\n",
    "- touch_screen: Has touchscreen or not\n",
    "- wifi: Has WiFi or not\n",
    "\n",
    "Your task is to use similarity-based and probability-based learning models to predict the price range of the phone (See `price_range` feature). Below you will find a code snippet to read and describe the dataset. Please make sure your notebook is in the same folder as the dataset file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1238.518500</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>1.522250</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>4.309500</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>32.046500</td>\n",
       "      <td>0.501750</td>\n",
       "      <td>140.249000</td>\n",
       "      <td>4.520500</td>\n",
       "      <td>...</td>\n",
       "      <td>645.108000</td>\n",
       "      <td>1251.515500</td>\n",
       "      <td>2124.213000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>5.767000</td>\n",
       "      <td>11.011000</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>439.418206</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>4.341444</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>...</td>\n",
       "      <td>443.780811</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>0.426273</td>\n",
       "      <td>0.500116</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>1.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>851.750000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>874.750000</td>\n",
       "      <td>1207.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2146.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1615.250000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>947.250000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>3064.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3998.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power       blue  clock_speed     dual_sim           fc  \\\n",
       "count    2000.000000  2000.0000  2000.000000  2000.000000  2000.000000   \n",
       "mean     1238.518500     0.4950     1.522250     0.509500     4.309500   \n",
       "std       439.418206     0.5001     0.816004     0.500035     4.341444   \n",
       "min       501.000000     0.0000     0.500000     0.000000     0.000000   \n",
       "25%       851.750000     0.0000     0.700000     0.000000     1.000000   \n",
       "50%      1226.000000     0.0000     1.500000     1.000000     3.000000   \n",
       "75%      1615.250000     1.0000     2.200000     1.000000     7.000000   \n",
       "max      1998.000000     1.0000     3.000000     1.000000    19.000000   \n",
       "\n",
       "            four_g   int_memory        m_dep    mobile_wt      n_cores  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.521500    32.046500     0.501750   140.249000     4.520500  ...   \n",
       "std       0.499662    18.145715     0.288416    35.399655     2.287837  ...   \n",
       "min       0.000000     2.000000     0.100000    80.000000     1.000000  ...   \n",
       "25%       0.000000    16.000000     0.200000   109.000000     3.000000  ...   \n",
       "50%       1.000000    32.000000     0.500000   141.000000     4.000000  ...   \n",
       "75%       1.000000    48.000000     0.800000   170.000000     7.000000  ...   \n",
       "max       1.000000    64.000000     1.000000   200.000000     8.000000  ...   \n",
       "\n",
       "         px_height     px_width          ram         sc_h         sc_w  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    645.108000  1251.515500  2124.213000    12.306500     5.767000   \n",
       "std     443.780811   432.199447  1084.732044     4.213245     4.356398   \n",
       "min       0.000000   500.000000   256.000000     5.000000     0.000000   \n",
       "25%     282.750000   874.750000  1207.500000     9.000000     2.000000   \n",
       "50%     564.000000  1247.000000  2146.500000    12.000000     5.000000   \n",
       "75%     947.250000  1633.000000  3064.500000    16.000000     9.000000   \n",
       "max    1960.000000  1998.000000  3998.000000    19.000000    18.000000   \n",
       "\n",
       "         talk_time      three_g  touch_screen         wifi  price_range  \n",
       "count  2000.000000  2000.000000   2000.000000  2000.000000  2000.000000  \n",
       "mean     11.011000     0.761500      0.503000     0.507000     1.500000  \n",
       "std       5.463955     0.426273      0.500116     0.500076     1.118314  \n",
       "min       2.000000     0.000000      0.000000     0.000000     0.000000  \n",
       "25%       6.000000     1.000000      0.000000     0.000000     0.750000  \n",
       "50%      11.000000     1.000000      1.000000     1.000000     1.500000  \n",
       "75%      16.000000     1.000000      1.000000     1.000000     2.250000  \n",
       "max      20.000000     1.000000      1.000000     1.000000     3.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import utility libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_feature = 'price_range'\n",
    "df = pd.read_csv('mppp_data.csv')\n",
    "\n",
    "#df.info()\n",
    "#df.head(20)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Identify outliers using the IQR method and replace outliers using the clamping technique. (10 pts)\n",
    "In this part, you will first identify the continuous features (interval and ratio scale), then identify outliers for these features using the interquartile range (IQR) method. The IQR, a measure of statistical dispersion, is the range between third and first quartile ($IQR = Q3-Q1$) and upper and lower bounds for the outliers can be set as:\n",
    " - $lower = Q1 - 1.5IQR$\n",
    " - $upper = Q3 + 1.5IQR$\n",
    "\n",
    "You will apply this clamp transformation only to the continious descriptive features and not to the categorical ones. In the end of this question, you will create a new data frame where outliers from continuous features are clamped (`cl_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************** battery_power ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** clock_speed ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** fc ****************************\n",
      "number of outliers: \n",
      "18\n",
      "max outlier value: \n",
      "19\n",
      "min outlier value: \n",
      "17\n",
      "**************************** int_memory ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** m_dep ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** mobile_wt ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** n_cores ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** pc ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** px_height ****************************\n",
      "number of outliers: \n",
      "2\n",
      "max outlier value: \n",
      "1960\n",
      "min outlier value: \n",
      "1949\n",
      "**************************** px_width ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** ram ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** sc_h ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** sc_w ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n",
      "**************************** talk_time ****************************\n",
      "number of outliers: \n",
      "0\n",
      "max outlier value: \n",
      "nan\n",
      "min outlier value: \n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# manually identify the categorical and continuous features, and put the column names in the lists below \n",
    "\n",
    "cont_features = [\"battery_power\", \"clock_speed\", \"fc\",\"int_memory\",\n",
    "                \"m_dep\", \"mobile_wt\", \"n_cores\", \"pc\", \"px_height\", \"px_width\", \"ram\",\n",
    "                \"sc_h\", \"sc_w\", 'talk_time']\n",
    "cat_features = [\"blue\", \"dual_sim\", \"four_g\", \"three_g\", \"touch_screen\", \"wifi\"]\n",
    "\n",
    "cl_df = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "##FIND OUTLIERS IN CONT FEATURES \n",
    "# your answer goes here\n",
    "def find_outliers_IQR(cl_df):\n",
    "    q1=cl_df.quantile(0.25)\n",
    "    q3=cl_df.quantile(0.75)\n",
    "    \n",
    "    IQR=q3-q1\n",
    "    \n",
    "    outliers = cl_df[((cl_df<(q1-1.5*IQR)) | (cl_df>(q3+1.5*IQR)))]\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "for each_feature in cont_features:\n",
    "    outliers = find_outliers_IQR(cl_df[each_feature])\n",
    "    print('****************************', each_feature, '****************************')\n",
    "\n",
    "    print(\"number of outliers: \\n\" + str(len(outliers)))\n",
    "\n",
    "    print(\"max outlier value: \\n\" + str(outliers.max()))\n",
    "\n",
    "    print(\"min outlier value: \\n\" + str(outliers.min()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery_power min value:  501 max:  1998\n",
      "clock_speed min value:  0.5 max:  3.0\n",
      "fc min value:  0 max:  19\n",
      "int_memory min value:  2 max:  64\n",
      "m_dep min value:  0.1 max:  1.0\n",
      "mobile_wt min value:  80 max:  200\n",
      "n_cores min value:  1 max:  8\n",
      "pc min value:  0 max:  20\n",
      "px_height min value:  0 max:  1960\n",
      "px_width min value:  500 max:  1998\n",
      "ram min value:  256 max:  3998\n",
      "sc_h min value:  5 max:  19\n",
      "sc_w min value:  0 max:  18\n",
      "talk_time min value:  2 max:  20\n"
     ]
    }
   ],
   "source": [
    "#CLAMPING THE OUTLIERS\n",
    "for each_feature in cont_features: \n",
    "    one_five_iqr = 1.5 * (cl_df[each_feature].quantile(0.75) - cl_df[each_feature].quantile(0.25))\n",
    "    q1 = cl_df[each_feature].quantile(0.25)\n",
    "    q3 = cl_df[each_feature].quantile(0.75)\n",
    "    min = q1 - one_five_iqr\n",
    "    max = q3 + one_five_iqr\n",
    "    \n",
    "    cl_df.loc[cl_df[each_feature]< min, each_feature] = min\n",
    "    cl_df.loc[cl_df[each_feature] > max, each_feature] = max\n",
    "    \n",
    "    print(each_feature, 'min value: ',df[each_feature].min(), 'max: ',df[each_feature].max())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756.0</td>\n",
       "      <td>2549</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2631</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>2603</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>2769</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1411</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1067</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>3220</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>700</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174.0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>836.0</td>\n",
       "      <td>1099</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>513</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>769.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>182.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>248</td>\n",
       "      <td>874.0</td>\n",
       "      <td>3946</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.5</td>\n",
       "      <td>177.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>3826</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1815.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.6</td>\n",
       "      <td>159.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>607</td>\n",
       "      <td>748.0</td>\n",
       "      <td>1482</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>803.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>344</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>2680</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1866.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>0.7</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>356</td>\n",
       "      <td>563.0</td>\n",
       "      <td>373</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>775.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.7</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>862</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>568</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>838.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.1</td>\n",
       "      <td>196.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>984</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>3554</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>595.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>441</td>\n",
       "      <td>810.0</td>\n",
       "      <td>3752</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>658</td>\n",
       "      <td>878.0</td>\n",
       "      <td>1835</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>682.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>902</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>2337</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0           842.0     0          2.2         0   1       0           7    0.6   \n",
       "1          1021.0     1          0.5         1   0       1          53    0.7   \n",
       "2           563.0     1          0.5         1   2       1          41    0.9   \n",
       "3           615.0     1          2.5         0   0       0          10    0.8   \n",
       "4          1821.0     1          1.2         0  13       1          44    0.6   \n",
       "5          1859.0     0          0.5         1   3       0          22    0.7   \n",
       "6          1821.0     0          1.7         0   4       1          10    0.8   \n",
       "7          1954.0     0          0.5         1   0       0          24    0.8   \n",
       "8          1445.0     1          0.5         0   0       0          53    0.7   \n",
       "9           509.0     1          0.6         1   2       1           9    0.1   \n",
       "10          769.0     1          2.9         1   0       0           9    0.1   \n",
       "11         1520.0     1          2.2         0   5       1          33    0.5   \n",
       "12         1815.0     0          2.8         0   2       0          33    0.6   \n",
       "13          803.0     1          2.1         0   7       0          17    1.0   \n",
       "14         1866.0     0          0.5         0  13       1          52    0.7   \n",
       "15          775.0     0          1.0         0   3       0          46    0.7   \n",
       "16          838.0     0          0.5         0   1       1          13    0.1   \n",
       "17          595.0     0          0.9         1   7       1          23    0.1   \n",
       "18         1131.0     1          0.5         1  11       0          49    0.6   \n",
       "19          682.0     1          0.5         0   4       0          19    1.0   \n",
       "\n",
       "    mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0       188.0        2  ...         20     756.0  2549   9.0   7.0         19   \n",
       "1       136.0        3  ...        905    1988.0  2631  17.0   3.0          7   \n",
       "2       145.0        5  ...       1263    1716.0  2603  11.0   2.0          9   \n",
       "3       131.0        6  ...       1216    1786.0  2769  16.0   8.0         11   \n",
       "4       141.0        2  ...       1208    1212.0  1411   8.0   2.0         15   \n",
       "5       164.0        1  ...       1004    1654.0  1067  17.0   1.0         10   \n",
       "6       139.0        8  ...        381    1018.0  3220  13.0   8.0         18   \n",
       "7       187.0        4  ...        512    1149.0   700  16.0   3.0          5   \n",
       "8       174.0        7  ...        386     836.0  1099  17.0   1.0         20   \n",
       "9        93.0        5  ...       1137    1224.0   513  19.0  10.0         12   \n",
       "10      182.0        5  ...        248     874.0  3946   5.0   2.0          7   \n",
       "11      177.0        8  ...        151    1005.0  3826  14.0   9.0         13   \n",
       "12      159.0        4  ...        607     748.0  1482  18.0   0.0          2   \n",
       "13      198.0        4  ...        344    1440.0  2680   7.0   1.0          4   \n",
       "14      185.0        1  ...        356     563.0   373  14.0   9.0          3   \n",
       "15      159.0        2  ...        862    1864.0   568  17.0  15.0         11   \n",
       "16      196.0        8  ...        984    1850.0  3554  10.0   9.0         19   \n",
       "17      121.0        3  ...        441     810.0  3752  10.0   2.0         18   \n",
       "18      101.0        5  ...        658     878.0  1835  19.0  13.0         16   \n",
       "19      121.0        4  ...        902    1064.0  2337  11.0   1.0         18   \n",
       "\n",
       "    three_g  touch_screen  wifi  price_range  \n",
       "0         0             0     1            1  \n",
       "1         1             1     0            2  \n",
       "2         1             1     0            2  \n",
       "3         1             0     0            2  \n",
       "4         1             1     0            1  \n",
       "5         1             0     0            1  \n",
       "6         1             0     1            3  \n",
       "7         1             1     1            0  \n",
       "8         1             0     0            0  \n",
       "9         1             0     0            0  \n",
       "10        0             0     0            3  \n",
       "11        1             1     1            3  \n",
       "12        1             0     0            1  \n",
       "13        1             0     1            2  \n",
       "14        1             0     1            0  \n",
       "15        1             1     1            0  \n",
       "16        1             0     1            3  \n",
       "17        1             1     0            3  \n",
       "18        1             1     0            1  \n",
       "19        0             1     1            1  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Normalize the data using range normalization (10 pts)\n",
    "In this part, you are expected to use the clamped dataset in the previous question (`cl_df`). Using sklearn's range normalization procedure (i.e., `MinMaxScaler`), initialize a scaler and normalize your features to [0,1] range. Do not include the target feature in your range normalization operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cl_df from Question 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for each_feature in cont_features: \n",
    "    model = scaler.fit(cl_df[[each_feature]])\n",
    "    cl_df[[each_feature]] = model.transform(cl_df[[each_feature]])\n",
    "\n",
    "#cl_df[cont_features].describe()\n",
    "\n",
    "cl_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Create a Nearest Neighbor classifier for classification (10 pts)\n",
    "Using sklearn's k-nearest neighbors classifier (`KNeighborsClassifier`), initialize a similarity-based classification model. Set the number of nearest neighbors (`n_neighbors`) parameter to 1. Then, train and test the error rate of your classifier. Use 67% of the data for training and the rest (33%) for testing. Set the random state to the last two digits of your Panther ID (if it has leading 0s, remove them). You are expected to use the clamped and normalized data frame that you generated in Q2.\n",
    "\n",
    "Print your accuracy score on testing dataset (Note: You can use `accuracy_score` from `sklearn.metrics`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(cl_df[cont_features + cat_features], cl_df['price_range'], \n",
    "                                                    train_size=0.67, test_size=0.33, \n",
    "                                                    random_state=54)\n",
    "nn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "nn_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1NN accuracy score (after normalization) 0.364\n"
     ]
    }
   ],
   "source": [
    "y_pred = nn_clf.predict(X_test)\n",
    "print('1NN accuracy score (after normalization) {:.3f}'.format(accuracy_score(y_pred, Y_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Searching for the best $k$ (20 points)\n",
    "Using the same training and testing dataset in Q3, find the training and testing accuracy for different $k$ values ( for each $k$ where $2 \\geq k \\geq 150$. \n",
    "\n",
    "To get the training accuracy, run `predict()` function of the classifier on training data and compare it with the target feature list from training set. To get the testing accuracy, apply the same `predict()` function, this time to testing data and compare it with the labels of the instances in the test set. The difference is that, we used training data to train the model, while the testing data is unseen to the model. \n",
    "\n",
    "Collect the training and testing accuracy scores for each $k$ and plot a line chart to show how they deviate as we increase the $k$ value.\n",
    "\n",
    "Discuss which $k$ value is more suitable, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'k'), Text(0, 0.5, 'Accuracy')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultsKNN = pd.DataFrame(columns=['KNN', 'Score for Training', 'Score for Testing'])\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(cl_df[cont_features + cat_features], cl_df['price_range'], \n",
    "                                                    train_size=0.67, test_size=0.33, \n",
    "                                                    random_state=54)\n",
    "\n",
    "for knnCount in range (2,151):\n",
    "    knn = KNeighborsClassifier(n_neighbors=knnCount, p=1, metric='minkowski') #manhattan dist here\n",
    "    knn.fit(X_train, Y_train)\n",
    "    y_train_pred = knn.predict(X_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    scoreTrain = accuracy_score(Y_train, y_train_pred)\n",
    "    scoreTest = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "    resultsKNN.loc[knnCount] = [knnCount, scoreTrain, scoreTest]\n",
    "\n",
    "resultsKNN.pop('KNN')\n",
    "ax = resultsKNN.plot()\n",
    "ax.set(xlabel='k', ylabel='Accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score for Training</th>\n",
       "      <th>Score for Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.702985</td>\n",
       "      <td>0.698485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Score for Training  Score for Testing\n",
       "147            0.702985           0.698485"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsKNN[resultsKNN['Score for Training']==resultsKNN['Score for Training'].max()]\n",
    "resultsKNN[resultsKNN['Score for Testing']==resultsKNN['Score for Testing'].max()]\n",
    "\n",
    "#The maximum score the training and testing occurs when k = 147. \n",
    "#Thus having k=147 would be the best for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Impact of Minkowski orders on kNN Classifiers (20 points)\n",
    "\n",
    "In this part, you will repeat the same experiment in Q4 (i.e., find how changing $k$ impact the accuracy) in combination with Minkowski order parameter (`p`). In other words, you will use the generalized Minkowski distance instead of the default Euclidean distance (where $p = 2$), which can be calculated as\n",
    "\n",
    "$Minkowski(q, ins, p) = (\\sum( |q_j-ins_j|^p ))^{\\frac{1}{p}}$\n",
    "\n",
    "\n",
    "For each $k \\in [2, 150]$ and for each $p \\in [1,4]$ find the training and testing accuracy scores. You can do that by alternating `p` and `n_neighbors` parameters in `KNeighborsClassifier`. \n",
    "\n",
    "Similar to Q3, collect training and testing accuracy scores and plot 4 line charts for each different value of `p`.\n",
    "\n",
    "Overall, which Minkowski order value is better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = []\n",
    "s = []\n",
    "st = []\n",
    "ps = []\n",
    "resultsKNN = pd.DataFrame(columns=['k', 'p', 'accuracy_test', 'accuracy_train'])\n",
    "for p in range(1,5):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cl_df[cont_features+cat_features], cl_df['price_range'], test_size=0.33, random_state=54)\n",
    "    for k in range(2,151):\n",
    "        neighbors = KNeighborsClassifier(n_neighbors=k, p=p)\n",
    "        neighbors.fit(x_train, y_train)\n",
    "        ks.append(k)\n",
    "        s.append(accuracy_score(y_test, neighbors.predict(x_test)))\n",
    "        st.append(accuracy_score(y_train, neighbors.predict(x_train)))\n",
    "        ps.append(p)\n",
    "\n",
    "resultsKNN['k'] = ks\n",
    "resultsKNN['accuracy_test'] = s\n",
    "resultsKNN['accuracy_train'] = st\n",
    "resultsKNN['p'] = ps\n",
    "resultsKNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsKNN[resultsKNN['accuracy_test']==resultsKNN['accuracy_test'].max()]\n",
    "resultsKNN[resultsKNN['accuracy_train']==resultsKNN['accuracy_train'].max()]\n",
    "\n",
    "#We reach maximum accuracy scores when p=1, so it's better when we set this minkowski value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "\n",
    "for p in range(1,5):\n",
    "    resultsKNN[resultsKNN['p']==p].plot(x='k', y='accuracy', ax=ax, label='p = '+str(p), ylabel=\"Accuracy\", xlabel=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Using a Probability-based Classifier (20 points)\n",
    "\n",
    "In this part, we will utilize probability-based Naive Bayes classifiers to perform mobile phone price range prediction. The same dataset partitions (with the same training/testing sampling ratio and random seed from Q3) will be used to compare the models. \n",
    "\n",
    "We will start with discretizing the continuous features (please use the list you prepared in Q1). For each continuous feature in the given dataset, create an ordinal variable using equi-frequency binning that will take the integer values (3 [->high], 2 [->medium], 1 [->low]). Do not transform the categorical variables.\n",
    "\n",
    "After applying discretization on continuous features, build a Naive Bayes classifier. In this case, use the Categorical Naive Bayes classifier (`CategoricalNB` from `sklearn.naive_bayes` module). Display the accuracy score on testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "def bin(column):\n",
    "    length = len(column)\n",
    "    l1 = int(length/3)\n",
    "    l2 = int(length*2/3)\n",
    "    return column.apply(lambda x: 1 if x < column[l1] else (2 if x < column[l2] else 3))\n",
    "   \n",
    "    \n",
    "NBc_df = cl_df.copy()\n",
    "\n",
    "for each_feature in NBc_df:\n",
    "    NBc_df.sort_values(by=each_feature, inplace=True)\n",
    "    NBc_df[each_feature] = bin(NBc_df[each_feature])\n",
    "\n",
    "NBc_df\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(NBc_df[cont_features+cat_features], NBc_df['price_range'], test_size=0.33,train_size=0.67, random_state=54)\n",
    "Nbc = CategoricalNB()\n",
    "Nbc.fit(x_train, y_train)\n",
    "\n",
    "y_pred = Nbc.predict(x_test)\n",
    "print(\"Gaussian NB Accuracy: {0:.2f}\".format( accuracy_score(y_test,y_pred) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Using a Gaussian Naive Bayes Classifier (20 points)\n",
    "Another alternative to the Categorical Naive Bayes classifier is the Gaussian Naive Bayes classifier. Unlike the Categorical Naive Bayes, Gaussian Naive Bayes classification algorithm utilizes a typical assumption that the continuous values associated with each target feature level are distributed according to a normal distribution.\n",
    "\n",
    "Using the original dataset (you can read the original dataset from the csv file again) construct a Gaussian Naive Bayes model (`GaussianNB` from `sklearn.naive_bayes` module). Display the accuracy score on testing dataset. Use the same training/testing dataset partitions and compare your result with the Categorical Naive Bayes model from Q6. \n",
    "\n",
    "Which model is better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#Setup X and y data\n",
    "X = cl_df[cont_features + cat_features]\n",
    "y = df['price_range']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,train_size=0.67,random_state=54)\n",
    "\n",
    "#Fit model\n",
    "_nbc = GaussianNB(priors = None)\n",
    "_nbc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = _nbc.predict(X_test)\n",
    "print(\"Gaussian NB Accuracy: {0:.2f}\".format( accuracy_score(y_test,y_pred) ))\n",
    "\n",
    "\n",
    "#The Categorical Naive Baye's model is better because it has a higher accuracy score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
