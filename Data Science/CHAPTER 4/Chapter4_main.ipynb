{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16beFe8589Sd"
   },
   "source": [
    "# Data Pre-processing in Python\n",
    "\n",
    "Some text some text\n",
    "Some text\n",
    "Lorem ipsum\n",
    " etc\n",
    " etc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_Jw5TyH-wPI"
   },
   "source": [
    "First start with importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zLBC9rYE8_tm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFA4TPeP-39i"
   },
   "source": [
    "**Reading Data from CSV file**\n",
    "Then, read the Motor Insurance Fraud Claim data to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 21232,
     "status": "ok",
     "timestamp": 1579814032557,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "X2bxyEvV5q6V",
    "outputId": "c4238914-a383-4a53-a103-1eb94b7343b9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# this is only needed for this google colab\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m abt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/My Drive/data/MotorInsuranceFraudClaimABTFull.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# this is only needed for this google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "abt_path = '/content/drive/My Drive/data/MotorInsuranceFraudClaimABTFull.csv'\n",
    "\n",
    "# for your local jupyter notebook, simply use the abs. or rel. path for the file\n",
    "# comment out above code.\n",
    "#abt_path = '[PATH TO YOUR FILE!]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvAfxwvxBwpT"
   },
   "source": [
    "Now read the csv file using the `pd`. `df` is the variable name of the data frame. `df.head()` shows the first few records (default is 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1579814277386,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "6BqbrJYj64BL",
    "outputId": "827c4951-35ac-4701-ed9a-a5d1025b2634"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(abt_path, sep=',')\n",
    "# you can alternatively use index_col parameter when reading csv files.\n",
    "# df = pd.read_csv(abt_path, sep=',', index_col='ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ua4iBoXCVgB"
   },
   "source": [
    "`df.dtypes` would return all the column names and their data types (int64, float64, or object).\n",
    "`df.info()` provides a more complex view with number of non-null values, data types etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1579542389467,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "3Mmt-bdnCVqb",
    "outputId": "ef3ab25a-08aa-489f-db80-afd0c1e35be5"
   },
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB5VHBUxEt6s"
   },
   "source": [
    "**Iterating over Data Frames**\n",
    "\n",
    "While it is not advisible, sometimes you may eventually need to iterate through records in your data frame. You can use `df.iterrows()`, `df.itertuples()`, or `df.iteritems()` to iterate. `iterrows()` returns a Series object per each row, and generally the slowest. `itertuples()` and `iteritems()` lets you iterate over row and column series as named tuples. We can use a `for` loop for iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1579544103429,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "0sEP1TBUEuEP",
    "outputId": "8789e8ca-208b-4c89-bc80-f2765510c16f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index, end=' ')\n",
    "    print(row) # uncomment this to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK-9KV3fKpdV"
   },
   "source": [
    "Checking the basics of your data. For every column in the data frame, we can count the records (`df[name].size`), count NULL values (`sum(df[name].isnull().sum())`), and unique values (`df[name].unique().size`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1579545127377,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "ZKGZgoarKplU",
    "outputId": "5fcba24a-ee17-41e3-d594-faa50131d1fe"
   },
   "outputs": [],
   "source": [
    "# We will use df.iteritems() as it allows us to iterate through columns\n",
    "for (name, series) in df.iteritems():\n",
    "  print('ANALYZING THE COLUMN:', name)\n",
    "  print('\\tTotal number of records', series.size)\n",
    "  print('\\tNumber of missing values', series.isnull().sum())\n",
    "  print('\\tPercentage of missing values {0}%'.format(((series.isnull().sum()/series.size)*100)) )\n",
    "  print('\\tNumber of unique values', series.unique().size)\n",
    "\n",
    "#alternatively, you can iterate over df.columns (column names) and access the columns\n",
    "# for name in df.columns:\n",
    "#   print('ANALYZING THE COLUMN:', name)\n",
    "#   print('\\tTotal number of records', df[name].size)\n",
    "#   print('\\tNumber of missing values', df[name].isnull().sum())\n",
    "#   print('\\tPercentage of missing values {0}%'.format(((df[name].isnull().sum()/df[name].size)*100)) )\n",
    "#   print('\\tNumber of unique values', df[name].unique().size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4JSM1WiQE1r"
   },
   "source": [
    "**Handling Missing Values**\n",
    "\n",
    "For a larger DataFrame, it can be tedious to look for missing values manually. In this case, we can use the `isnull()` method to return a DataFrame with Boolean values that indicate whether a cell contains a numeric value (False) or if data is missing (True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1579545605166,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "AQKip3OuQFAh",
    "outputId": "04d86e3e-5455-4e7a-cc25-7d81c3550e37"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3E7WN1aRQal2"
   },
   "source": [
    "Rows with missing values can be easily dropped via the `dropna()` method. Please, note significant data reduction â€“ we went from 7,000 cells to 2,338 cells. `df.size` returns *(row-count x column-count)* when called for the entire DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1579545949657,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "GJ4csXksQatj",
    "outputId": "28c7a75f-8e40-42a0-8c8a-9f144cc801ea"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "print('Number of cells before dropping rows with missing values: {}'.format(df.size))\n",
    "print()\n",
    "dfrd = df.dropna() # drop values with null values and re-assign\n",
    "print(dfrd.isnull().sum())\n",
    "print('Number of cells after dropping rows with missing values: {}'.format(dfrd.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TyuWTkfRySD"
   },
   "source": [
    "Instead of dropping rows, we can also drop columns with null values by setting the `axis` argument to 1, *i.e.*, `df = df.dropna(axis=1)`. This time we will use `df.shape` for feedback, as it returns separate counts for both dimensions of DataFrame, that is the (row-count, column-count) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1579546188843,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "CjLLY2UWSJBI",
    "outputId": "9784f3fc-9c05-412f-d6ee-a0d466206215"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "print('Number of cells before dropping columns with missing values: {}'.format(df.size))\n",
    "print()\n",
    "dfcd = df.dropna(axis=1) # drop columns with row values (axis=1 signifies columns)\n",
    "print(dfcd.isnull().sum())\n",
    "print('Number of cells after dropping columns with missing values: {}'.format(dfcd.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giKN5pfHUMdc"
   },
   "source": [
    "**Imputation:**\n",
    "We can also replace each NaN value by the corresponding mean which is separately calculated for each feature column. Other options for this strategy are replacing with median or most frequent, which is useful for categorical feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1579582236872,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "t2XL-e76U9DA",
    "outputId": "e38c8b83-28f6-4311-cb09-29f634a0fcb6"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputed_df = df.copy()\n",
    "imputed_df['Num Soft Tissue'] = mean_imputer.fit_transform(df[['Num Soft Tissue']])\n",
    "# Note here that we cannot use mean for Marital Status, simply because it is not a numeric attribute\n",
    "print('\\tTotal number of missing values in original df', df.isnull().sum().sum())\n",
    "print('\\tTotal number of missing values after imputation (for number of soft tissue)', imputed_df.isnull().sum().sum())\n",
    "\n",
    "#There is a much more straightforward way for mean imputation but above can be used with much more flexible options\n",
    "#df.apply(lambda x: x.fillna(x.mean()),axis=0) # this assumes all numerical values and uses lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iM-nSSyqdA0t"
   },
   "source": [
    "**Histograms**\n",
    "\n",
    "We used `df.dtype` and `df.info()` before. We will be iterating through the entire dataframe again, but only selecting the attributes that are different than object. \n",
    "\n",
    "We import a popular plotting library `matplotlib` to generate\n",
    "histograms and then save each of them in a separate PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "smakTc_hdUJ3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 693
    },
    "executionInfo": {
     "elapsed": 2140,
     "status": "ok",
     "timestamp": 1579583397909,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "qqIEKf_udfoU",
    "outputId": "839d84ac-6796-48e3-aa14-ccb1fcbe3561"
   },
   "outputs": [],
   "source": [
    "col_list = []\n",
    "for (name, series) in df.iteritems():\n",
    "  if series.dtype != 'object':\n",
    "    col_list.append(name)\n",
    "\n",
    "fig, ax = plt.subplots(2,5,figsize=(18,8)) # get a bigger figure\n",
    "df_for_hist = df[col_list]\n",
    "df_for_hist.hist(bins=20, alpha=0.5, ax=ax) # note here that you may change the bin size to see the distribution better.\n",
    "#you could also do the following\n",
    "# print(df.select_dtypes(exclude=['object']).hist(bins=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKpUYUpugiaW"
   },
   "source": [
    "**Box Plots**\n",
    "\n",
    "A box plot displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum.\n",
    "In a box plot, we draw a box from the first quartile to the third quartile. A vertical line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "executionInfo": {
     "elapsed": 1374,
     "status": "ok",
     "timestamp": 1579814665712,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "c_zyyeevP3Af",
    "outputId": "12a608c0-c707-42ea-d6c6-be0dde7d94f6"
   },
   "outputs": [],
   "source": [
    "# Let's get the numeric data again, with another handy function\n",
    "df_for_bp = df._get_numeric_data()\n",
    "\n",
    "#you can plot one by one\n",
    "plt.boxplot(df_for_bp['ID'])\n",
    "plt.show()\n",
    "\n",
    "# or you can use pandas-provided wrapper.\n",
    "# df_for_bp.boxplot(column=['Total Claimed', 'Num Claims'])\n",
    "df_for_bp.boxplot(column=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kt1UP2DjSu-h"
   },
   "source": [
    "The above-presented box-plots for ID column shows a nicely spread values, very similar to a normal distribution. However, we cannot infer that right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1201,
     "status": "ok",
     "timestamp": 1579815217641,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "YWKTP2LoS20I",
    "outputId": "ca6acb10-582a-4478-882d-66d170bb83f0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_for_bp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's consider claim amount\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf_for_bp\u001b[49m\u001b[38;5;241m.\u001b[39mboxplot(column\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClaim Amount\u001b[39m\u001b[38;5;124m'\u001b[39m], vert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#horizontal box-plot\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Let's also see the values used in the five-number summary\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLAIM AMOUNT\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_for_bp' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's consider claim amount\n",
    "df_for_bp.boxplot(column=['Claim Amount'], vert=False) #horizontal box-plot\n",
    "\n",
    "# Let's also see the values used in the five-number summary\n",
    "print('CLAIM AMOUNT')\n",
    "print('\\tMin value:{}'.format(df_for_bp['Claim Amount'].min())) # minimum\n",
    "print('\\t1st Quartile value:{}'.format(df_for_bp['Claim Amount'].quantile(0.25))) # First quartile\n",
    "print('\\tMedian value:{}'.format(df_for_bp['Claim Amount'].median())) # median\n",
    "print('\\t3rd Quartile value:{}'.format(df_for_bp['Claim Amount'].quantile(0.75))) # Third quartile\n",
    "print('\\tMax value:{}'.format(df_for_bp['Claim Amount'].max())) # maximum\n",
    "\n",
    "# additional descriptive statistics\n",
    "print('\\tMean value:{}'.format(df_for_bp['Claim Amount'].mean())) # mean\n",
    "print('\\tStd. Dev. value:{}'.format(df_for_bp['Claim Amount'].std())) # std dev\n",
    "print('\\tVariance value:{}'.format(df_for_bp['Claim Amount'].var())) # variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py4_TqdZVBI0"
   },
   "source": [
    "**Scatter Plots**\n",
    "\n",
    "A scatter plot is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1579815470074,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "TlFdBXO3VNGL",
    "outputId": "482f7317-e747-43d4-b7d7-f449261209e9"
   },
   "outputs": [],
   "source": [
    "df_scatter = df._get_numeric_data()\n",
    "\n",
    "#let's use classical method\n",
    "plt.scatter(x=df_scatter['Income of Policy Holder'], y=df_scatter['Claim Amount'])\n",
    "plt.xlabel('Income of Policy Holder')\n",
    "plt.ylabel('Claim Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1579815523172,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "jWWhqcChVzEN",
    "outputId": "64736db2-593b-4f72-9b38-39c0c0e70d4f"
   },
   "outputs": [],
   "source": [
    "# we can also use pandas wrapper\n",
    "df_scatter.plot(kind='scatter', x='Income of Policy Holder', y='Claim Amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "executionInfo": {
     "elapsed": 6498,
     "status": "ok",
     "timestamp": 1579816018202,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "rifUYGqJWGJJ",
    "outputId": "479f0712-f382-49b2-ad59-0d9e6136ea9e"
   },
   "outputs": [],
   "source": [
    "# We can also create a scatter plot matrix (SPLOM). \n",
    "# Seaborn, which is a visualization library, provides a high-level interface for these.\n",
    "import seaborn as sns\n",
    "\n",
    "df_concise = df_scatter[ ['Income of Policy Holder', 'Claim Amount', 'Claim Amount Received', 'Fraud Flag'] ]\n",
    "\n",
    "# sns.set(style='ticks')\n",
    "sns.pairplot(df_concise, hue='Fraud Flag', markers=['+', 'o']) # hue is for mapping plot aspects to different colors.\n",
    "\n",
    "# you can use the following to see the full pairplot\n",
    "# sns.pairplot(df_scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9uylbuLYC8f"
   },
   "source": [
    "**Heatmap of Correlation Matrix**\n",
    "\n",
    "A heat map is a graphical representation of data where the individual values contained in a matrix are represented as colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1579816212111,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "FJCl7rfGYMyy",
    "outputId": "e623dce7-f828-40c0-d061-79a86408818e"
   },
   "outputs": [],
   "source": [
    "correlations = df_concise.corr()\n",
    "sns.heatmap(correlations)\n",
    "print(correlations.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvRZ5rGeY-ld"
   },
   "source": [
    "**Min-max Normalization**\n",
    "is the simplest method and consists in rescaling the range of features to scale the range in [0, 1] or [âˆ’1, 1]. Selecting the target range depends on the nature of the data. The general formula for a min-max of [0, 1] is given as:\n",
    "\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 1152,
     "status": "ok",
     "timestamp": 1579818502307,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "bOmzTKcwZL0F",
    "outputId": "74710dce-e2ae-440c-b72f-5ab96af9cbe6"
   },
   "outputs": [],
   "source": [
    "# we will use scikit-learn library for normalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df_minmax = df_concise # for quicker illustration\n",
    "print(df_minmax.head())\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "a_scaled = min_max_scaler.fit_transform(df_minmax) #a_scaled is an N-d numpy array now. We need to create a new dataframe off of it\n",
    "df_scaled = pd.DataFrame(data=a_scaled, columns=df_minmax.columns)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhwqjtyEjaPS"
   },
   "source": [
    "**Z-score Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1579819169126,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "edQzK6qWjdlr",
    "outputId": "a52929f4-6c8a-44e9-9180-960e0ec812e9"
   },
   "outputs": [],
   "source": [
    "zs_scaler = preprocessing.StandardScaler()\n",
    "zs_scaled = zs_scaler.fit_transform(df_minmax)\n",
    "df_zscaled = pd.DataFrame(data=zs_scaled, columns=df_minmax.columns)\n",
    "df_zscaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84Fo55aqku_G"
   },
   "source": [
    "**Equal-width Binning**\n",
    "\n",
    "We can use the histogram function of `numpy`:\n",
    "\n",
    "`count,division = np.histogram(series)`\n",
    "\n",
    "where `division` is the automatically calculated border for your bins and `count` is the population inside each bin. We have equal-width bins setup as [min, max] range with linearly spaced 5 markers (i.e., this results in 4 bin between the markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1579820011779,
     "user": {
      "displayName": "Berkay Aydin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAXb-gJgX1GjM7_cKTRNUp-OXZCTyVVF2uZYO9auw=s64",
      "userId": "06026467748375287015"
     },
     "user_tz": 300
    },
    "id": "fc0qnqkgkuIr",
    "outputId": "faf8d3a1-9972-4508-b847-e4a1c703d957"
   },
   "outputs": [],
   "source": [
    "count, division = np.histogram(df['Claim Amount'], bins=5)\n",
    "division"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJv0tRP0Kwc3Td7ZgzEQix",
   "collapsed_sections": [],
   "name": "Chapter4_main.ipynb",
   "provenance": [
    {
     "file_id": "1DDwf5aYIv3Je3inQAbsTQQLvehVOtfMN",
     "timestamp": 1631542317676
    },
    {
     "file_id": "1ATEh0GiJReeH1vi4zlAkFs4JuGuI90eW",
     "timestamp": 1579546273310
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
